2019-03-04 11:29:25.559139: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-03-04 11:29:25.562933: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUresult(-1)
2019-03-04 11:29:25.562982: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: gpu01.nitkhpc.local
2019-03-04 11:29:25.562993: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: gpu01.nitkhpc.local
2019-03-04 11:29:25.563121: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
2019-03-04 11:29:25.563160: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  375.26  Thu Dec  8 18:36:43 PST 2016
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) 
"""
2019-03-04 11:29:25.563197: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 375.26.0
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 256, 256, 1)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 256, 256, 64)      640       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 128, 128, 64)      36928     
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 128, 128, 128)     73856     
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 64, 64, 128)       147584    
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 64, 64, 256)       295168    
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 32, 32, 256)       590080    
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 32, 32, 512)       1180160   
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 32, 32, 256)       1179904   
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 32, 32, 128)       295040    
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 64, 64, 128)       0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 64, 64, 64)        73792     
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 128, 128, 64)      0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 128, 128, 32)      18464     
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 128, 128, 2)       578       
_________________________________________________________________
up_sampling2d_3 (UpSampling2 (None, 256, 256, 2)       0         
=================================================================
Total params: 3,892,194
Trainable params: 3,892,194
Non-trainable params: 0
_________________________________________________________________
Epoch 1/1

 1/71 [..............................] - ETA: 41:17 - loss: 0.0152
 2/71 [..............................] - ETA: 45:06 - loss: 0.4848
 3/71 [>.............................] - ETA: 50:50 - loss: 0.3703
 4/71 [>.............................] - ETA: 49:00 - loss: 0.3177
 5/71 [=>............................] - ETA: 46:19 - loss: 0.2567
 6/71 [=>............................] - ETA: 44:15 - loss: 0.2161
 7/71 [=>............................] - ETA: 42:57 - loss: 0.1867
 8/71 [==>...........................] - ETA: 43:57 - loss: 0.1646
 9/71 [==>...........................] - ETA: 44:49 - loss: 0.1475
10/71 [===>..........................] - ETA: 45:35 - loss: 0.1337
11/71 [===>..........................] - ETA: 47:11 - loss: 0.1226
12/71 [====>.........................] - ETA: 48:08 - loss: 0.1132
13/71 [====>.........................] - ETA: 46:29 - loss: 0.1054
14/71 [====>.........................] - ETA: 44:49 - loss: 0.0985
15/71 [=====>........................] - ETA: 43:19 - loss: 0.0926
16/71 [=====>........................] - ETA: 41:56 - loss: 0.0875
17/71 [======>.......................] - ETA: 40:38 - loss: 0.0829
18/71 [======>.......................] - ETA: 39:24 - loss: 0.0788
19/71 [=======>......................] - ETA: 38:14 - loss: 0.0753
20/71 [=======>......................] - ETA: 37:09 - loss: 0.0721
21/71 [=======>......................] - ETA: 36:05 - loss: 0.0691
22/71 [========>.....................] - ETA: 35:01 - loss: 0.0665
23/71 [========>.....................] - ETA: 34:02 - loss: 0.0640
24/71 [=========>....................] - ETA: 33:03 - loss: 0.0618
25/71 [=========>....................] - ETA: 32:06 - loss: 0.0598
26/71 [=========>....................] - ETA: 31:14 - loss: 0.0578
27/71 [==========>...................] - ETA: 30:22 - loss: 0.0561
28/71 [==========>...................] - ETA: 29:31 - loss: 0.0544
29/71 [===========>..................] - ETA: 28:42 - loss: 0.0530
30/71 [===========>..................] - ETA: 27:53 - loss: 0.0515
31/71 [============>.................] - ETA: 27:04 - loss: 0.0502
32/71 [============>.................] - ETA: 26:16 - loss: 0.0489
33/71 [============>.................] - ETA: 25:30 - loss: 0.0478
34/71 [=============>................] - ETA: 24:43 - loss: 0.0466
35/71 [=============>................] - ETA: 23:58 - loss: 0.0456
36/71 [==============>...............] - ETA: 23:13 - loss: 0.0447
37/71 [==============>...............] - ETA: 22:28 - loss: 0.0438
38/71 [===============>..............] - ETA: 21:44 - loss: 0.0429
39/71 [===============>..............] - ETA: 21:02 - loss: 0.0421
40/71 [===============>..............] - ETA: 20:19 - loss: 0.0412
41/71 [================>.............] - ETA: 19:36 - loss: 0.0405
42/71 [================>.............] - ETA: 18:54 - loss: 0.0398
43/71 [=================>............] - ETA: 18:11 - loss: 0.0391
44/71 [=================>............] - ETA: 17:30 - loss: 0.0384
45/71 [==================>...........] - ETA: 16:49 - loss: 0.0378
46/71 [==================>...........] - ETA: 16:08 - loss: 0.0372
47/71 [==================>...........] - ETA: 15:28 - loss: 0.0366
48/71 [===================>..........] - ETA: 14:48 - loss: 0.0361
49/71 [===================>..........] - ETA: 14:08 - loss: 0.0355
50/71 [====================>.........] - ETA: 13:28 - loss: 0.0351
51/71 [====================>.........] - ETA: 12:48 - loss: 0.0346
52/71 [====================>.........] - ETA: 12:09 - loss: 0.0341
53/71 [=====================>........] - ETA: 11:29 - loss: 0.0337
54/71 [=====================>........] - ETA: 10:50 - loss: 0.0333
55/71 [======================>.......] - ETA: 10:11 - loss: 0.0329
56/71 [======================>.......] - ETA: 9:32 - loss: 0.0325 
57/71 [=======================>......] - ETA: 8:53 - loss: 0.0321
58/71 [=======================>......] - ETA: 8:14 - loss: 0.0317
59/71 [=======================>......] - ETA: 7:36 - loss: 0.0314
60/71 [========================>.....] - ETA: 6:57 - loss: 0.0310
61/71 [========================>.....] - ETA: 6:19 - loss: 0.0307
62/71 [=========================>....] - ETA: 5:40 - loss: 0.0304
63/71 [=========================>....] - ETA: 5:02 - loss: 0.0300
64/71 [==========================>...] - ETA: 4:24 - loss: 0.0298
65/71 [==========================>...] - ETA: 3:46 - loss: 0.0295
66/71 [==========================>...] - ETA: 3:08 - loss: 0.0292
67/71 [===========================>..] - ETA: 2:30 - loss: 0.0289
68/71 [===========================>..] - ETA: 1:52 - loss: 0.0286
69/71 [============================>.] - ETA: 1:15 - loss: 0.0284
70/71 [============================>.] - ETA: 37s - loss: 0.0281 
71/71 [==============================] - 2662s 37s/step - loss: 0.0279

128/465 [=======>......................] - ETA: 14s
256/465 [===============>..............] - ETA: 8s 
384/465 [=======================>......] - ETA: 3s
465/465 [==============================] - 19s 42ms/step
/opt/ohpc/pub/anaconda3/5.0.1/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
/opt/ohpc/pub/anaconda3/5.0.1/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
/opt/ohpc/pub/anaconda3/5.0.1/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8
  .format(dtypeobj_in, dtypeobj_out))
0.010965553430780288
