2019-03-04 10:56:45.384011: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-03-04 10:56:45.387784: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUresult(-1)
2019-03-04 10:56:45.387831: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: gpu01.nitkhpc.local
2019-03-04 10:56:45.387842: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: gpu01.nitkhpc.local
2019-03-04 10:56:45.387912: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
2019-03-04 10:56:45.387949: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  375.26  Thu Dec  8 18:36:43 PST 2016
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) 
"""
2019-03-04 10:56:45.387980: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 375.26.0
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 256, 256, 1)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 256, 256, 64)      640       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 128, 128, 64)      36928     
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 128, 128, 128)     73856     
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 64, 64, 128)       147584    
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 64, 64, 256)       295168    
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 32, 32, 256)       590080    
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 32, 32, 512)       1180160   
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 32, 32, 256)       1179904   
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 32, 32, 128)       295040    
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 64, 64, 128)       0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 64, 64, 64)        73792     
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 128, 128, 64)      0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 128, 128, 32)      18464     
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 128, 128, 2)       578       
_________________________________________________________________
up_sampling2d_3 (UpSampling2 (None, 256, 256, 2)       0         
=================================================================
Total params: 3,892,194
Trainable params: 3,892,194
Non-trainable params: 0
_________________________________________________________________
Epoch 1/1

 1/71 [..............................] - ETA: 35:35 - loss: 0.1041
 2/71 [..............................] - ETA: 29:45 - loss: 0.5482
 3/71 [>.............................] - ETA: 27:36 - loss: 0.6905
 4/71 [>.............................] - ETA: 26:20 - loss: 0.7693
 5/71 [=>............................] - ETA: 25:25 - loss: 0.8144
 6/71 [=>............................] - ETA: 24:39 - loss: 0.8451
 7/71 [=>............................] - ETA: 24:01 - loss: 0.8661
 8/71 [==>...........................] - ETA: 23:26 - loss: 0.8820
 9/71 [==>...........................] - ETA: 22:57 - loss: 0.8597
10/71 [===>..........................] - ETA: 22:28 - loss: 0.8079
11/71 [===>..........................] - ETA: 22:01 - loss: 0.7358
12/71 [====>.........................] - ETA: 21:37 - loss: 0.6860
13/71 [====>.........................] - ETA: 21:12 - loss: 0.6343
14/71 [====>.........................] - ETA: 20:46 - loss: 0.5904
15/71 [=====>........................] - ETA: 20:21 - loss: 0.5517
16/71 [=====>........................] - ETA: 19:57 - loss: 0.5180
17/71 [======>.......................] - ETA: 19:33 - loss: 0.4882
18/71 [======>.......................] - ETA: 19:10 - loss: 0.4617
19/71 [=======>......................] - ETA: 18:46 - loss: 0.4380
20/71 [=======>......................] - ETA: 18:23 - loss: 0.4167
21/71 [=======>......................] - ETA: 18:00 - loss: 0.3973
22/71 [========>.....................] - ETA: 17:37 - loss: 0.3798
23/71 [========>.....................] - ETA: 17:15 - loss: 0.3637
24/71 [=========>....................] - ETA: 16:52 - loss: 0.3490
25/71 [=========>....................] - ETA: 16:30 - loss: 0.3354
26/71 [=========>....................] - ETA: 16:07 - loss: 0.3228
27/71 [==========>...................] - ETA: 15:45 - loss: 0.3112
28/71 [==========>...................] - ETA: 15:23 - loss: 0.3004
29/71 [===========>..................] - ETA: 15:01 - loss: 0.2904
30/71 [===========>..................] - ETA: 14:39 - loss: 0.2811
31/71 [============>.................] - ETA: 14:17 - loss: 0.2724
32/71 [============>.................] - ETA: 13:55 - loss: 0.2642
33/71 [============>.................] - ETA: 13:34 - loss: 0.2564
34/71 [=============>................] - ETA: 13:12 - loss: 0.2492
35/71 [=============>................] - ETA: 12:50 - loss: 0.2424
36/71 [==============>...............] - ETA: 12:29 - loss: 0.2359
37/71 [==============>...............] - ETA: 12:07 - loss: 0.2298
38/71 [===============>..............] - ETA: 11:46 - loss: 0.2240
39/71 [===============>..............] - ETA: 11:24 - loss: 0.2186
40/71 [===============>..............] - ETA: 11:02 - loss: 0.2135
41/71 [================>.............] - ETA: 10:41 - loss: 0.2085
42/71 [================>.............] - ETA: 10:19 - loss: 0.2038
43/71 [=================>............] - ETA: 9:59 - loss: 0.1993 
44/71 [=================>............] - ETA: 9:37 - loss: 0.1950
45/71 [==================>...........] - ETA: 9:16 - loss: 0.1909
46/71 [==================>...........] - ETA: 8:55 - loss: 0.1870
47/71 [==================>...........] - ETA: 8:34 - loss: 0.1832
48/71 [===================>..........] - ETA: 8:13 - loss: 0.1796
49/71 [===================>..........] - ETA: 7:51 - loss: 0.1762
50/71 [====================>.........] - ETA: 7:30 - loss: 0.1728
51/71 [====================>.........] - ETA: 7:09 - loss: 0.1696
52/71 [====================>.........] - ETA: 6:47 - loss: 0.1666
53/71 [=====================>........] - ETA: 6:26 - loss: 0.1636
54/71 [=====================>........] - ETA: 6:04 - loss: 0.1608
55/71 [======================>.......] - ETA: 5:43 - loss: 0.1581
56/71 [======================>.......] - ETA: 5:21 - loss: 0.1554
57/71 [=======================>......] - ETA: 5:00 - loss: 0.1529
58/71 [=======================>......] - ETA: 4:39 - loss: 0.1504
59/71 [=======================>......] - ETA: 4:17 - loss: 0.1481
60/71 [========================>.....] - ETA: 3:56 - loss: 0.1458
61/71 [========================>.....] - ETA: 3:34 - loss: 0.1435
62/71 [=========================>....] - ETA: 3:13 - loss: 0.1414
63/71 [=========================>....] - ETA: 2:51 - loss: 0.1393
64/71 [==========================>...] - ETA: 2:30 - loss: 0.1373
65/71 [==========================>...] - ETA: 2:08 - loss: 0.1354
66/71 [==========================>...] - ETA: 1:47 - loss: 0.1335
67/71 [===========================>..] - ETA: 1:25 - loss: 0.1316
68/71 [===========================>..] - ETA: 1:04 - loss: 0.1298
69/71 [============================>.] - ETA: 42s - loss: 0.1281 
70/71 [============================>.] - ETA: 21s - loss: 0.1264
71/71 [==============================] - 1526s 21s/step - loss: 0.1248

128/465 [=======>......................] - ETA: 13s
256/465 [===============>..............] - ETA: 8s 
384/465 [=======================>......] - ETA: 3s
465/465 [==============================] - 19s 41ms/step
/opt/ohpc/pub/anaconda3/5.0.1/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
/opt/ohpc/pub/anaconda3/5.0.1/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
/opt/ohpc/pub/anaconda3/5.0.1/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8
  .format(dtypeobj_in, dtypeobj_out))
0.011368780282716597
