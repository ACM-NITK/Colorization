{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
    "from skimage.io import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "image = img_to_array(load_img('brush.png'))\n",
    "image = np.array(image, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import map images into the lab colorspace\n",
    "X = rgb2lab(1.0/255*image)[:,:,0]\n",
    "Y = rgb2lab(1.0/255*image)[:,:,1:]\n",
    "Y = Y / 128\n",
    "X = X.reshape(1, 512, 512, 1)\n",
    "Y = Y.reshape(1, 512, 512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(512, 512, 1)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 8)       80        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 8)       584       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 256, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 32)      9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 256, 256, 16)      4624      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 512, 512, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 512, 512, 2)       290       \n",
      "=================================================================\n",
      "Total params: 32,202\n",
      "Trainable params: 32,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1760\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.9103\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.1742\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.1202\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0875\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0793\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0835\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0779\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0692\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0668\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0662\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0658\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0652\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0645\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0638\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0633\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0632\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0632\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0630\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0626\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0624\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0621\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0622\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0623\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0619\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0615\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0612\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0611\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0609\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0606\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0603\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0600\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0598\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0597\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0594\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0591\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0588\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0586\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0583\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0579\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0577\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0573\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0570\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0567\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.0564\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0560\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0556\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0553\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0549\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0545\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0542\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0538\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0534\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0531\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0526\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0523\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0519\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0515\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0511\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0507\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0504\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0500\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0496\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0493\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.0489\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0486\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0483\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.0479\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0476\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0472\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0469\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0466\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0463\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.0459\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.0456\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0454\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0451\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0448\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.0445\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0443\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0441\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0437\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0435\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0433\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0435\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0436\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0426\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0433\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0423\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0426\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0418\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0419\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0431\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0426\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0413\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0423\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0411\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0418\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0407\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0412\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0406\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0405\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0402\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0401\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.0398\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0396\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0396\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0393\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0392\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0389\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0388\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0384\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0383\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0381\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0380\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0377\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0376\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0373\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0371\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0372\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0368\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0367\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0363\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0363\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0360\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0358\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0356\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0353\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0352\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0349\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0347\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0345\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0343\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0340\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0339\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0342\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0342\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0336\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0338\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0333\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0334\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0333\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0327\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0328\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0322\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0320\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0314\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0313\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0309\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0307\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0303\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0311\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0305\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0299\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0301\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0294\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0298\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0296\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0285\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0311\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0287\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0286\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0287\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0284\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0277\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0288\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0333\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0338\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0314\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0315\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0304\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0288\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0305\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0273\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0282\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0288\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0276\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0280\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0290\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0266\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0292\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0312\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0283\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0291\n",
      "Epoch 185/1000\n"
     ]
    }
   ],
   "source": [
    "# Finish model\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "\n",
    "#Train the neural network\n",
    "model.fit(x=X, y=Y, batch_size=1, epochs=1000)\n",
    "print(model.evaluate(X, Y, batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output colorizations\n",
    "output = model.predict(X)\n",
    "output = output * 128\n",
    "canvas = np.zeros((512, 512, 3))\n",
    "canvas[:,:,0] = X[0][:,:,0]\n",
    "canvas[:,:,1:] = output[0]\n",
    "imsave(\"img_result.png\", lab2rgb(canvas))\n",
    "imsave(\"img_gray_scale.png\", rgb2gray(lab2rgb(canvas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
